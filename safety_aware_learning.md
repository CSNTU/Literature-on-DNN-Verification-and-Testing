<head>
  <meta charset="utf-8">

  <meta name="description" content="DNN Verification and Testing: Attacking Techniques">
  <meta name="author" content="SitePoint">

  <link rel="stylesheet" href="css/styles.css?v=1.0">

  <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.js"></script>
  <![endif]-->
</head>

<body>
  
  <h2>DNN Verification and Testing: Interpretability </h2>
  
<table class="tg">

  <tr>
    <th class="tg-yw4l"> Title </th> 
    <th> Link </th>    
    <th class="tg-yw4l"> Comment </th> 
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Safe Model-based Reinforcement Learning with Stability Guarantees </th> 
    <th> <a href="http://papers.nips.cc/paper/6692-safe-model-based-reinforcement-learning-with-stability-guarantees">link</a> </th>    
    <th class="tg-yw4l"> NIPS2017 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Safe Exploration in Finite Markov Decision Processes with Gaussian Processes </th> 
    <th> <a href="http://papers.nips.cc/paper/6358-safe-exploration-in-finite-markov-decision-processes-with-gaussian-processes">link</a> </th>    
    <th class="tg-yw4l"> NIPS2017 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Adversarial Spheres </th> 
    <th> <a href="https://arxiv.org/abs/1801.02774">link</a> </th>    
    <th class="tg-yw4l"> ICLR2018 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Certifying Some Distributional Robustness with Principled Adversarial Training </th> 
    <th> <a href="https://arxiv.org/abs/1710.10571">link</a> </th>    
    <th class="tg-yw4l"> ICLR2018 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms </th> 
    <th> <a href="https://arxiv.org/abs/1602.02389">link</a> </th>    
    <th class="tg-yw4l"> ICLR2018 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Stable Distribution Alignment Using the Dual of the Adversarial Distance </th> 
    <th> <a href="https://arxiv.org/abs/1707.04046">link</a> </th>    
    <th class="tg-yw4l"> ICLR2018 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Adversarial Machine Learning at Scale </th> 
    <th> <a href="https://arxiv.org/abs/1611.01236">link</a> </th>    
    <th class="tg-yw4l"> ICLR2017 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Adversarial Training Methods for Semi-Supervised Text Classification </th> 
    <th> <a href="https://arxiv.org/abs/1605.07725">link</a> </th>    
    <th class="tg-yw4l"> ICLR2017 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l">EPOpt - Learning Robust Neural Network Policies Using Model Ensembles </th> 
    <th> <a href="https://arxiv.org/abs/1610.01283">link</a> </th>    
    <th class="tg-yw4l"> ICLR2017 </th>   
  </tr>

  <tr>
    <th class="tg-yw4l">On Robust Concepts and Small Neural Nets </th> 
    <th> <a href="https://openreview.net/forum?id=SyZprb5xg">link</a> </th>    
    <th class="tg-yw4l"> ICLR2017 </th>   
  </tr>
  
  
  <tr>
    <th class="tg-yw4l">Tighter bounds lead to improved classifiers </th> 
    <th> <a href="https://arxiv.org/abs/1606.09202">link</a> </th>    
    <th class="tg-yw4l"> ICLR2017 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l">On the Stability of Deep Networks </th> 
    <th> <a href="https://arxiv.org/abs/1412.5896">link</a> </th>    
    <th class="tg-yw4l"> ICLR2015 </th>   
  </tr>
  
    
</table>

<a href="https://github.com/TrustAI/Literature-on-DNN-Verification-and-Testing">Back</a>
  
</body>
</html>
