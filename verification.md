<head>
  <meta charset="utf-8">

  <meta name="description" content="DNN Verification and Testing: Attacking Techniques">
  <meta name="author" content="SitePoint">

  <link rel="stylesheet" href="css/styles.css?v=1.0">

  <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.js"></script>
  <![endif]-->
</head>

<body>
  
  <h2>DNN Verification and Testing: Verification Techniques </h2>
  
<table class="tg" align="left">

  <tr>
    <th class="tg-yw4l"> Title </th> 
    <th> Link </th>    
    <th class="tg-yw4l"> Comment </th> 
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Safety Verification of Deep Neural Networks </th> 
    <th> <a href="https://arxiv.org/abs/1610.06940">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
    
  <tr>
    <th class="tg-yw4l"> Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks </th> 
    <th> <a href="https://arxiv.org/abs/1702.01135">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Provable defenses against adversarial examples via the convex outer adversarial polytope </th> 
    <th> <a href="https://arxiv.org/abs/1711.00851">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Formal Verification of Piece-Wise Linear Feed-Forward Neural Networks </th> 
    <th> <a href="https://arxiv.org/abs/1705.01320">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Feature-Guided Black-Box Safety Testing of Deep Neural Networks </th> 
    <th> <a href="https://arxiv.org/abs/1710.07859">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Verification of Binarized Neural Networks via Inter-Neuron Factoring </th> 
    <th> <a href="https://arxiv.org/abs/1710.03107">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> A Unified View of Piecewise Linear Neural Network Verification </th> 
    <th> <a href="https://arxiv.org/abs/1711.00455">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Output Range Analysis for Deep Neural Networks </th> 
    <th> <a href="https://arxiv.org/abs/1709.09130">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Global Robustness Evaluation of Deep Neural Networks with Provable Guarantees for L0 Norm </th> 
    <th> <a href="https://arxiv.org/abs/1804.05805">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Output Reachable Set Estimation and Verification for Multi-Layer Neural Networks </th> 
    <th> <a href="https://arxiv.org/abs/1708.03322">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Formal Security Analysis of Neural Networks using Symbolic Intervals </th> 
    <th> <a href="https://arxiv.org/abs/1804.10829">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Reachable Set Estimation and Verification for Neural Network Models of Nonlinear Dynamic Systems </th> 
    <th> <a href="https://arxiv.org/abs/1802.03557">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> AI2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation </th> 
    <th> <a href="http://ai2.ethz.ch/files/ai2.pdf">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
    
</table>

<a href="https://github.com/TrustAI/Literature-on-DNN-Verification-and-Testing">Back</a>
  
</body>
</html>
