<head>
  <meta charset="utf-8">

  <meta name="description" content="DNN Verification and Testing: Attacking Techniques">
  <meta name="author" content="SitePoint">

  <link rel="stylesheet" href="css/styles.css?v=1.0">

  <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.js"></script>
  <![endif]-->
</head>

<body>
  
  <h2>DNN Verification and Testing: Verification Techniques </h2>
  
<table class="tg" align="left">

  <tr>
    <th class="tg-yw4l"> Title </th> 
    <th> Link </th>    
    <th class="tg-yw4l"> Comment </th> 
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Safety Verification of Deep Neural Networks </th> 
    <th> <a href="https://arxiv.org/abs/1610.06940">link</a> </th>    
    <th class="tg-yw4l"> DLV; CAV2018 </th>   
  </tr>
    
  <tr>
    <th class="tg-yw4l"> Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks </th> 
    <th> <a href="https://arxiv.org/abs/1702.01135">link</a> </th>    
    <th class="tg-yw4l">  CAV2018 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Provable defenses against adversarial examples via the convex outer adversarial polytope </th> 
    <th> <a href="https://arxiv.org/abs/1711.00851">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Formal Verification of Piece-Wise Linear Feed-Forward Neural Networks </th> 
    <th> <a href="https://arxiv.org/abs/1705.01320">link</a> </th>    
    <th class="tg-yw4l"> ATVA2017 </th>   
  </tr>

   <tr>
    <th class="tg-yw4l"> Maximum Resilience of Artificial Neural Networks. </th> 
    <th> <a href="https://arxiv.org/pdf/1705.01040.pdf">link</a> </th>   
    <th class="tg-yw4l"> ATVA2017 </th>   
  </tr>
    
  <tr>
    <th class="tg-yw4l"> Feature-Guided Black-Box Safety Testing of Deep Neural Networks </th> 
    <th> <a href="https://arxiv.org/abs/1710.07859">link</a> </th>    
    <th class="tg-yw4l"> SafeCV; TACAS2018 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Verification of Binarized Neural Networks via Inter-Neuron Factoring </th> 
    <th> <a href="https://arxiv.org/abs/1710.03107">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> A Unified View of Piecewise Linear Neural Network Verification </th> 
    <th> <a href="https://arxiv.org/abs/1711.00455">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Output Range Analysis for Deep Neural Networks </th> 
    <th> <a href="https://arxiv.org/abs/1709.09130">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>

  <tr>
    <th class="tg-yw4l"> Output Range Analysis for Deep Feedforward Neural Networks </th> 
    <th> <a href="https://pdfs.semanticscholar.org/d2df/6969b185a4017048f996d0e7cd1859c24e67.pdf?_ga=2.213261138.75527587.1529600372-1684338043.1526379056">link</a> </th>    
    <th class="tg-yw4l"> NFM2018 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Global Robustness Evaluation of Deep Neural Networks with Provable Guarantees for L0 Norm </th> 
    <th> <a href="https://arxiv.org/abs/1804.05805">link</a> </th>    
    <th class="tg-yw4l"> L0-TRE </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Output Reachable Set Estimation and Verification for Multi-Layer Neural Networks </th> 
    <th> <a href="https://arxiv.org/abs/1708.03322">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Formal Security Analysis of Neural Networks using Symbolic Intervals </th> 
    <th> <a href="https://arxiv.org/abs/1804.10829">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Reachable Set Estimation and Verification for Neural Network Models of Nonlinear Dynamic Systems </th> 
    <th> <a href="https://arxiv.org/abs/1802.03557">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> AI2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation </th> 
    <th> <a href="http://ai2.ethz.ch/files/ai2.pdf">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Reachability Analysis of Deep Neural Networks with Provable Guarantees </th> 
    <th> <a href="https://arxiv.org/abs/1805.02242">link</a> </th>    
    <th class="tg-yw4l"> DeepGO </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach </th> 
    <th> <a href="https://openreview.net/forum?id=BkUHlMZ0b">link</a> </th>    
    <th class="tg-yw4l"> CLEVER </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Extracting Automata from Recurrent Neural Networks Using Queries and Counterexamples </th> 
    <th> <a href="https://arxiv.org/abs/1711.09576">link</a> </th>    
    <th class="tg-yw4l"> ICML2018 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Lipschitz Continuity in Model-based Reinforcement Learning </th> 
    <th> <a href="https://arxiv.org/abs/1804.07193">link</a> </th>    
    <th class="tg-yw4l"> ICML2018 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Differentiable Abstract Interpretation for Provably Robust Neural Networks </th> 
    <th> <a href="">link</a> </th>    
    <th class="tg-yw4l"> ICML2018 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Global optimization of Lipschitz functions </th> 
    <th> <a href="http://proceedings.mlr.press/v70/malherbe17a.html">link</a> </th>    
    <th class="tg-yw4l"> ICML2017 </th>   
  </tr>
    
    
  <tr>
    <th class="tg-yw4l"> A ranking approach to global optimization </th> 
    <th> <a href="http://proceedings.mlr.press/v48/malherbe16.html">link</a> </th>    
    <th class="tg-yw4l"> ICML2016 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> BASC: Applying Bayesian Optimization to the Search for Global Minima on Potential Energy Surfaces </th> 
    <th> <a href="http://proceedings.mlr.press/v48/carr16.html">link</a> </th>    
    <th class="tg-yw4l"> ICML2016 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Lower bounds on the robustness to adversarial perturbations </th> 
    <th> <a href="http://papers.nips.cc/paper/6682-lower-bounds-on-the-robustness-to-adversarial-perturbations">link</a> </th>    
    <th class="tg-yw4l"> NIPS2017 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation </th> 
    <th> <a href="http://papers.nips.cc/paper/6821-formal-guarantees-on-the-robustness-of-a-classifier-against-adversarial-manipulation">link</a> </th>    
    <th class="tg-yw4l"> NIPS2017 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Measuring Neural Net Robustness with Constraints </th> 
    <th> <a href="http://papers.nips.cc/paper/6339-measuring-neural-net-robustness-with-constraints">link</a> </th>    
    <th class="tg-yw4l"> NIPS2017 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Controllable Invariance through Adversarial Feature Learning. </th> 
    <th> <a href="http://papers.nips.cc/paper/6661-controllable-invariance-through-adversarial-feature-learning.pdf">link</a> </th>   
    <th class="tg-yw4l"> NIPS2017 </th>   
  </tr>

</table>

<a href="https://github.com/TrustAI/Literature-on-DNN-Verification-and-Testing">Back</a>
  
</body>
</html>
