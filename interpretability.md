<head>
  <meta charset="utf-8">

  <meta name="description" content="DNN Verification and Testing: Attacking Techniques">
  <meta name="author" content="SitePoint">

  <link rel="stylesheet" href="css/styles.css?v=1.0">

  <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.js"></script>
  <![endif]-->
</head>

<body>
  
  <h2>DNN Verification and Testing: Interpretability </h2>
  
<table class="tg">

  <tr>
    <th class="tg-yw4l"> Title </th> 
    <th> Link </th>    
    <th class="tg-yw4l"> Comment </th> 
  </tr>
  
  <tr>
    <th class="tg-yw4l"> The Mythos of Model Interpretability </th> 
    <th> <a href="https://arxiv.org/abs/1606.03490">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Explanation Methods in Deep Learning: Users, Values, Concerns and Challenges </th> 
    <th> <a href="https://arxiv.org/abs/1803.07517">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> "Why Should I Trust You?": Explaining the Predictions of Any Classifier </th> 
    <th> <a href="https://arxiv.org/abs/1602.04938">link</a> </th>    
    <th class="tg-yw4l"> LIME  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Learning Important Features Through Propagating Activation Differences </th> 
    <th> <a href="https://arxiv.org/abs/1704.02685">link</a> </th>    
    <th class="tg-yw4l"> IMCL2017 -- DeepLIFT  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Rationalizing Neural Predictions </th> 
    <th> <a href="https://arxiv.org/abs/1606.04155">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Interpretable Explanations of Black Boxes by Meaningful Perturbation </th> 
    <th> <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Fong_Interpretable_Explanations_of_ICCV_2017_paper.pdf">link</a> </th>    
    <th class="tg-yw4l">   </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization </th> 
    <th> <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.pdf">link</a> </th>    
    <th class="tg-yw4l">   </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Methods for interpreting and understanding deep neural networks </th> 
    <th> <a href="https://www.sciencedirect.com/science/article/pii/S1051200417302385">link</a> </th>    
    <th class="tg-yw4l">   </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Understanding Black-box Predictions via Influence Functions </th> 
    <th> <a href="https://arxiv.org/abs/1703.04730">link</a> </th>    
    <th class="tg-yw4l"> ICML2017 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Axiomatic Attribution for Deep Networks </th> 
    <th> <a href="https://arxiv.org/abs/1703.01365">link</a> </th>    
    <th class="tg-yw4l"> ICML2017 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Beyond saliency: understanding convolutional neural networks from saliency prediction on layer-wise relevance propagation </th> 
    <th> <a href="https://arxiv.org/abs/1712.08268">link</a> </th>    
    <th class="tg-yw4l"> LRP </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> A Unified Approach to Interpreting Model Predictions </th> 
    <th> <a href="https://arxiv.org/abs/1705.07874">link</a> </th>    
    <th class="tg-yw4l"> NIPS2017, Shapley </th>   
  </tr>
    
  <tr>
    <th class="tg-yw4l"> Explanation and Justification in Machine Learning: A Survey </th> 
    <th> <a href="http://home.earthlink.net/~dwaha/research/meetings/ijcai17-xai/1.%20(Biran%20&%20Cotton%20XAI-17)%20Explanation%20and%20Justification%20in%20ML%20-%20A%20Survey.pdf">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Using Explanations to Improve Ensembling of Visual Question Answering Systems </th> 
    <th> <a href="http://home.earthlink.net/~dwaha/research/meetings/ijcai17-xai/7.%20(Rajani%20&%20Mooney%20XAI-17)%20Using%20Explanations%20to%20Improve%20Ensembling%20of%20VQA%20Systems.pdf">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> A simple neural network module for relational reasoning </th> 
    <th> <a href="https://arxiv.org/abs/1706.01427">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Examples are not Enough, Learn to Criticize! Criticism for Interpretability </th> 
    <th> <a href="http://papers.nips.cc/paper/6300-examples-are-not-enough-learn-to-criticize-criticism-for-interpretability">link</a> </th>    
    <th class="tg-yw4l"> NIPS2016 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> DeepVoting: A Robust and Explainable Deep Network for Semantic Part Detection under Partial Occlusion</th> 
    <th> <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_DeepVoting_A_Robust_CVPR_2018_paper.pdf">link</a> </th>   
    <th class="tg-yw4l">  </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Learning to Explain: An Information-Theoretic Perspective on Model Interpretation </th> 
    <th> <a href="https://arxiv.org/pdf/1802.07814.pdf">link</a> </th>   
    <th class="tg-yw4l"> ICML2018 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Variational Information Maximization for Feature Selection </th> 
    <th> <a href="https://arxiv.org/pdf/1606.02827.pdf">link</a> </th>   
    <th class="tg-yw4l">  </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Visualizing and Understanding Atari Agents </th> 
    <th> <a href="https://arxiv.org/pdf/1711.00138.pdf">link</a> </th>   
    <th class="tg-yw4l"> ICML2018 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV) </th> 
    <th> <a href="https://arxiv.org/abs/1711.11279">link</a> </th>   
    <th class="tg-yw4l"> ICML2018 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> MINE: Mutual Information Neural Estimation </th> 
    <th> <a href="https://arxiv.org/abs/1801.04062">link</a> </th>   
    <th class="tg-yw4l"> ICML2018 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Understanding the Representation and Computation of Multilayer Perceptrons: A Case Study in Speech Recognition </th> 
    <th> <a href="http://proceedings.mlr.press/v70/nagamine17a.html">link</a> </th>   
    <th class="tg-yw4l"> ICML2017 </th>   
  </tr>
    
   <tr>
    <th class="tg-yw4l"> Nonparanormal Information Estimation </th> 
    <th> <a href="http://proceedings.mlr.press/v70/singh17a.html">link</a> </th>   
    <th class="tg-yw4l"> ICML2017 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Estimating Mutual Information for Discrete-Continuous Mixtures. </th> 
    <th> <a href="http://papers.nips.cc/paper/7180-estimating-mutual-information-for-discrete-continuous-mixtures">link</a> </th>   
    <th class="tg-yw4l"> NIPS2017 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Interpretable Distribution Features with Maximum Testing Power. </th> 
    <th> <a href="http://papers.nips.cc/paper/6148-interpretable-distribution-features-with-maximum-testing-power">link</a> </th>   
    <th class="tg-yw4l"> NIPS2016 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Variational Information Maximization for Feature Selection. </th> 
    <th> <a href="http://papers.nips.cc/paper/6444-variational-information-maximization-for-feature-selection">link</a> </th>   
    <th class="tg-yw4l"> NIPS2016 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Efficient Nonparametric Smoothness Estimation. </th> 
    <th> <a href="http://papers.nips.cc/paper/6369-efficient-nonparametric-smoothness-estimation">link</a> </th>   
    <th class="tg-yw4l"> NIPS2016 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Finite-Sample Analysis of Fixed-k Nearest Neighbor Density Functional Estimators. </th> 
    <th> <a href="http://papers.nips.cc/paper/6123-finite-sample-analysis-of-fixed-k-nearest-neighbor-density-functional-estimators">link</a> </th>   
    <th class="tg-yw4l"> NIPS2016 </th>   
  </tr>

   <tr>
    <th class="tg-yw4l"> Learning Influence Functions from Incomplete Observations. </th> 
    <th> <a href="http://papers.nips.cc/paper/6181-learning-influence-functions-from-incomplete-observations">link</a> </th>   
    <th class="tg-yw4l"> NIPS2016 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Breaking the Bandwidth Barrier: Geometrical Adaptive Entropy Estimation. </th> 
    <th> <a href="http://papers.nips.cc/paper/6299-breaking-the-bandwidth-barrier-geometrical-adaptive-entropy-estimation">link</a> </th>   
    <th class="tg-yw4l"> NIPS2016 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Efficient Estimation of Mutual Information for Strongly Dependent Variables. </th> 
    <th> <a href="http://proceedings.mlr.press/v38/gao15.pdf">link</a> </th>   
    <th class="tg-yw4l"> AISTATS2015 </th>   
  </tr>

   <tr>
    <th class="tg-yw4l"> Estimating Mutual Information by Local Gaussian Approximation. </th> 
    <th> <a href="https://arxiv.org/abs/1508.00536">link</a> </th>   
    <th class="tg-yw4l"> UAI2015 </th>   
  </tr>
	
   <tr>
    <th class="tg-yw4l"> On Learning Sparse Boolean Formulae For Explaining AI Decisions. </th> 
    <th> <a href="http://susmitjha.github.io/papers/nasafm17-sparseboollearn.pdf">link</a> </th>   
    <th class="tg-yw4l"> NFM2017 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality</th> 
    <th> <a href="https://arxiv.org/abs/1801.02613">link</a> </th>   
    <th class="tg-yw4l">ICLR2018</th>   
  </tr> 

   <tr>
    <th class="tg-yw4l"> Decision Boundary Analysis of Adversarial Examples </th> 
    <th> <a href="https://openreview.net/forum?id=BkpiPMbA-">link</a> </th>   
    <th class="tg-yw4l">ICLR2018</th>   
  </tr> 
  
   <tr>
    <th class="tg-yw4l"> Intriguing Properties of Adversarial Examples </th> 
    <th> <a href="https://arxiv.org/abs/1711.02846">link</a> </th>   
    <th class="tg-yw4l">ICLR2018</th>   
  </tr> 
  
   <tr>
    <th class="tg-yw4l"> Robustness of Classifiers to Universal Perturbations - A Geometric Perspective </th> 
    <th> <a href="https://openreview.net/forum?id=ByrZyglCb">link</a> </th>   
    <th class="tg-yw4l">ICLR2018</th>   
  </tr> 
  
  <tr>
    <th class="tg-yw4l"> On the Limitation of Local Intrinsic Dimensionality for Characterizing the Subspaces of Adversarial Examples </th> 
    <th> <a href="https://arxiv.org/abs/1803.09638">link</a> </th>   
    <th class="tg-yw4l">ICLR2018</th>   
  </tr> 
  
   <tr>
    <th class="tg-yw4l"> Efficient Representation of Low-Dimensional Manifolds using Deep Networks </th> 
    <th> <a href="https://arxiv.org/abs/1602.04723">link</a> </th>   
    <th class="tg-yw4l">ICLR2017</th>   
  </tr> 
  
   <tr>
    <th class="tg-yw4l"> Understanding deep learning requires rethinking generalization </th> 
    <th> <a href="https://arxiv.org/abs/1611.03530">link</a> </th>   
    <th class="tg-yw4l">ICLR2017</th>   
  </tr> 
  
  <tr>
    <th class="tg-yw4l"> Why Deep Neural Networks for Function Approximation </th> 
    <th> <a href="https://arxiv.org/abs/1610.04161">link</a> </th>   
    <th class="tg-yw4l">ICLR2017</th>   
  </tr> 
  
  <tr>
    <th class="tg-yw4l"> Digging Deep into the layers of CNNs - In Search of How CNNs Achieve View Invariance </th> 
    <th> <a href="https://arxiv.org/abs/1508.01983">link</a> </th>   
    <th class="tg-yw4l">ICLR2016</th>   
  </tr> 
  
  <tr>
    <th class="tg-yw4l"> Data Representation and Compression Using Linear-Programming Approximations </th> 
    <th> <a href="https://arxiv.org/abs/1511.06606">link</a> </th>   
    <th class="tg-yw4l">ICLR2016</th>   
  </tr> 
  
  <tr>
    <th class="tg-yw4l"> The local low-dimensionality of natural images </th> 
    <th> <a href="https://arxiv.org/abs/1412.6626">link</a> </th>   
    <th class="tg-yw4l">ICLR2015</th>   
  </tr> 
  
  <tr>
    <th class="tg-yw4l"> Transformation Properties of Learned Visual Representations </th> 
    <th> <a href="https://arxiv.org/abs/1412.7659">link</a> </th>   
    <th class="tg-yw4l">ICLR2015</th>   
  </tr> 
  
  <tr>
    <th class="tg-yw4l"> Factorized sparse learning models with interpretable high order feature interactions</th> 
    <th> <a href="https://dl.acm.org/citation.cfm?id=2623747">link</a> </th>   
    <th class="tg-yw4l">KDD14</th>   
  </tr> 
  
   <tr>
    <th class="tg-yw4l"> Interpretable Decision Sets- A Joint Framework for Description and Prediction</th> 
    <th> <a href="https://dl.acm.org/citation.cfm?id=2939672.2939874">link</a> </th>   
    <th class="tg-yw4l">KDD16</th>   
  </tr> 
  
  
   <tr>
    <th class="tg-yw4l"> Interpretable Predictions of Tree-based Ensembles via Actionable Feature Tweaking</th> 
    <th> <a href="https://arxiv.org/abs/1706.06691">link</a> </th>   
    <th class="tg-yw4l">KDD17</th>   
  </tr> 
  
   <tr>
    <th class="tg-yw4l"> Utilizing temporal patterns for estimating uncertainty in interpretable early decision making</th> 
    <th> <a href="https://dl.acm.org/citation.cfm?id=2623694">link</a> </th>   
    <th class="tg-yw4l">KDD14</th>   
  </tr> 
  
  <tr>
    <th class="tg-yw4l"> Why Should I Trust You- Explaining the Predictions of Any Classifier</th> 
    <th> <a href="https://arxiv.org/abs/1602.04938">link</a> </th>   
    <th class="tg-yw4l">KDD16</th>   
  </tr> 

  <tr>
    <th class="tg-yw4l"> Towards a Mathematical Understanding of the Difficulty in Learning With Feedforward Neural Networks</th> 
    <th> <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Shen_Towards_a_Mathematical_CVPR_2018_paper.pdf">link</a> </th>   
    <th class="tg-yw4l">CVPR2018</th>   
  </tr> 

  <tr>
    <th class="tg-yw4l"> What Do Deep Networks Like to See?</th> 
    <th> <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Palacio_What_Do_Deep_CVPR_2018_paper.pdf">link</a> </th>   
    <th class="tg-yw4l">CVPR2018</th>   
  </tr> 

  <tr>
    <th class="tg-yw4l"> Perturbative Neural Networks</th> 
    <th> <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Juefei-Xu_Perturbative_Neural_Networks_CVPR_2018_paper.pdf">link</a> </th>   
    <th class="tg-yw4l">CVPR2018</th>   
  </tr> 

  <tr>
    <th class="tg-yw4l"> Empirical Study of the Topology and Geometry of Deep Networks</th> 
    <th> <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Fawzi_Empirical_Study_of_CVPR_2018_paper.pdf">link</a> </th>   
    <th class="tg-yw4l">CVPR2018</th>   
  </tr> 

  <tr>
    <th class="tg-yw4l"> Net2Vec: Quantifying and Explaining how Concepts are Encoded by Filters in Deep Neural Networks</th> 
    <th> <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Fong_Net2Vec_Quantifying_and_CVPR_2018_paper.pdf">link</a> </th>   
    <th class="tg-yw4l">CVPR2018</th>   
  </tr> 
	
</table>

<a href="https://github.com/TrustAI/Literature-on-DNN-Verification-and-Testing">Back</a>
  
</body>
</html>
