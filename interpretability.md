<head>
  <meta charset="utf-8">

  <meta name="description" content="DNN Verification and Testing: Attacking Techniques">
  <meta name="author" content="SitePoint">

  <link rel="stylesheet" href="css/styles.css?v=1.0">

  <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.js"></script>
  <![endif]-->
</head>

<body>
  
  <h2>DNN Verification and Testing: Interpretability </h2>
  
<table class="tg">

  <tr>
    <th class="tg-yw4l"> Title </th> 
    <th> Link </th>    
    <th class="tg-yw4l"> Comment </th> 
  </tr>
  
  <tr>
    <th class="tg-yw4l"> The Mythos of Model Interpretability </th> 
    <th> <a href="https://arxiv.org/abs/1606.03490">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Explanation Methods in Deep Learning: Users, Values, Concerns and Challenges </th> 
    <th> <a href="https://arxiv.org/abs/1803.07517">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> "Why Should I Trust You?": Explaining the Predictions of Any Classifier </th> 
    <th> <a href="https://arxiv.org/abs/1602.04938">link</a> </th>    
    <th class="tg-yw4l"> LIME  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Learning Important Features Through Propagating Activation Differences </th> 
    <th> <a href="https://arxiv.org/abs/1704.02685">link</a> </th>    
    <th class="tg-yw4l"> IMCL2017 -- DeepLIFT  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Rationalizing Neural Predictions </th> 
    <th> <a href="https://arxiv.org/abs/1606.04155">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Interpretable Explanations of Black Boxes by Meaningful Perturbation </th> 
    <th> <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Fong_Interpretable_Explanations_of_ICCV_2017_paper.pdf">link</a> </th>    
    <th class="tg-yw4l">   </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization </th> 
    <th> <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.pdf">link</a> </th>    
    <th class="tg-yw4l">   </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Methods for interpreting and understanding deep neural networks </th> 
    <th> <a href="https://www.sciencedirect.com/science/article/pii/S1051200417302385">link</a> </th>    
    <th class="tg-yw4l">   </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Understanding Black-box Predictions via Influence Functions </th> 
    <th> <a href="https://arxiv.org/abs/1703.04730">link</a> </th>    
    <th class="tg-yw4l"> ICML2017 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Axiomatic Attribution for Deep Networks </th> 
    <th> <a href="https://arxiv.org/abs/1703.01365">link</a> </th>    
    <th class="tg-yw4l"> ICML2017 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Beyond saliency: understanding convolutional neural networks from saliency prediction on layer-wise relevance propagation </th> 
    <th> <a href="https://arxiv.org/abs/1712.08268">link</a> </th>    
    <th class="tg-yw4l"> LRP </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> A Unified Approach to Interpreting Model Predictions </th> 
    <th> <a href="https://arxiv.org/abs/1705.07874">link</a> </th>    
    <th class="tg-yw4l"> NIPS2017, Shapley </th>   
  </tr>
    
  <tr>
    <th class="tg-yw4l"> Explanation and Justification in Machine Learning: A Survey </th> 
    <th> <a href="http://home.earthlink.net/~dwaha/research/meetings/ijcai17-xai/1.%20(Biran%20&%20Cotton%20XAI-17)%20Explanation%20and%20Justification%20in%20ML%20-%20A%20Survey.pdf">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Using Explanations to Improve Ensembling of Visual Question Answering Systems </th> 
    <th> <a href="http://home.earthlink.net/~dwaha/research/meetings/ijcai17-xai/7.%20(Rajani%20&%20Mooney%20XAI-17)%20Using%20Explanations%20to%20Improve%20Ensembling%20of%20VQA%20Systems.pdf">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> A simple neural network module for relational reasoning </th> 
    <th> <a href="https://arxiv.org/abs/1706.01427">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Examples are not Enough, Learn to Criticize! Criticism for Interpretability </th> 
    <th> <a href="http://papers.nips.cc/paper/6300-examples-are-not-enough-learn-to-criticize-criticism-for-interpretability">link</a> </th>    
    <th class="tg-yw4l"> NIPS2016 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> DeepVoting: A Robust and Explainable Deep Network for Semantic Part Detection under Partial Occlusion</th> 
    <th> <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_DeepVoting_A_Robust_CVPR_2018_paper.pdf">link</a> </th>   
    <th class="tg-yw4l">  </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Learning to Explain: An Information-Theoretic Perspective on Model Interpretation </th> 
    <th> <a href="https://arxiv.org/pdf/1802.07814.pdf">link</a> </th>   
    <th class="tg-yw4l"> ICML2018 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Visualizing and Understanding Atari Agents </th> 
    <th> <a href="https://arxiv.org/pdf/1711.00138.pdf">link</a> </th>   
    <th class="tg-yw4l"> ICML2018 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV) </th> 
    <th> <a href="https://arxiv.org/abs/1711.11279">link</a> </th>   
    <th class="tg-yw4l"> ICML2018 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> MINE: Mutual Information Neural Estimation </th> 
    <th> <a href="https://arxiv.org/abs/1801.04062">link</a> </th>   
    <th class="tg-yw4l"> ICML2018 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Understanding the Representation and Computation of Multilayer Perceptrons: A Case Study in Speech Recognition </th> 
    <th> <a href="http://proceedings.mlr.press/v70/nagamine17a.html">link</a> </th>   
    <th class="tg-yw4l"> ICML2017 </th>   
  </tr>
    
   <tr>
    <th class="tg-yw4l"> Nonparanormal Information Estimation </th> 
    <th> <a href="http://proceedings.mlr.press/v70/singh17a.html">link</a> </th>   
    <th class="tg-yw4l"> ICML2017 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Estimating Mutual Information for Discrete-Continuous Mixtures. </th> 
    <th> <a href="http://papers.nips.cc/paper/7180-estimating-mutual-information-for-discrete-continuous-mixtures">link</a> </th>   
    <th class="tg-yw4l"> NIPS2017 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Interpretable Distribution Features with Maximum Testing Power. </th> 
    <th> <a href="http://papers.nips.cc/paper/6148-interpretable-distribution-features-with-maximum-testing-power">link</a> </th>   
    <th class="tg-yw4l"> NIPS2016 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Variational Information Maximization for Feature Selection. </th> 
    <th> <a href="http://papers.nips.cc/paper/6444-variational-information-maximization-for-feature-selection">link</a> </th>   
    <th class="tg-yw4l"> NIPS2016 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Efficient Nonparametric Smoothness Estimation. </th> 
    <th> <a href="http://papers.nips.cc/paper/6369-efficient-nonparametric-smoothness-estimation">link</a> </th>   
    <th class="tg-yw4l"> NIPS2016 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Finite-Sample Analysis of Fixed-k Nearest Neighbor Density Functional Estimators. </th> 
    <th> <a href="http://papers.nips.cc/paper/6123-finite-sample-analysis-of-fixed-k-nearest-neighbor-density-functional-estimators">link</a> </th>   
    <th class="tg-yw4l"> NIPS2016 </th>   
  </tr>

   <tr>
    <th class="tg-yw4l"> Learning Influence Functions from Incomplete Observations. </th> 
    <th> <a href="http://papers.nips.cc/paper/6181-learning-influence-functions-from-incomplete-observations">link</a> </th>   
    <th class="tg-yw4l"> NIPS2016 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Breaking the Bandwidth Barrier: Geometrical Adaptive Entropy Estimation. </th> 
    <th> <a href="http://papers.nips.cc/paper/6299-breaking-the-bandwidth-barrier-geometrical-adaptive-entropy-estimation">link</a> </th>   
    <th class="tg-yw4l"> NIPS2016 </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Efficient Estimation of Mutual Information for Strongly Dependent Variables. </th> 
    <th> <a href="http://proceedings.mlr.press/v38/gao15.pdf">link</a> </th>   
    <th class="tg-yw4l"> AISTATS2015 </th>   
  </tr>

    
</table>

<a href="https://github.com/TrustAI/Literature-on-DNN-Verification-and-Testing">Back</a>
  
</body>
</html>
