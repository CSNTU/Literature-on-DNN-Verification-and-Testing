<head>
  <meta charset="utf-8">

  <meta name="description" content="DNN Verification and Testing: Attacking Techniques">
  <meta name="author" content="SitePoint">

  <link rel="stylesheet" href="css/styles.css?v=1.0">

  <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.js"></script>
  <![endif]-->
</head>

<body>

  <h2>DNN Verification and Testing: Attacking Techniques</h2>
  
<table class="tg">

  <tr>
    <th class="tg-yw4l"> Title </th> 
    <th> Link </th>    
    <th class="tg-yw4l"> Comment </th> 
  </tr>

  <tr>
    <th class="tg-yw4l"> Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks </th> 
    <th> <a href="https://arxiv.org/abs/1511.04508">link</a> </th>    
    <th class="tg-yw4l">  S&P2016 </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> Parseval Networks: Improving Robustness to Adversarial Examples </th> 
    <th> <a href="https://arxiv.org/abs/1704.08847">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
  <tr>
    <th class="tg-yw4l"> MagNet: A Two-Pronged Defense against Adversarial Examples </th> 
    <th> <a href="https://arxiv.org/abs/1705.09064">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Deflecting Adversarial Attacks with Pixel Deflection </th> 
    <th> <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Prakash_Deflecting_Adversarial_Attacks_CVPR_2018_paper.pdf">link</a> </th>   
    <th class="tg-yw4l">  </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Defense against Universal Adversarial Perturbations </th> 
    <th> <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Akhtar_Defense_Against_Universal_CVPR_2018_paper.pdf">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Defense against Adversarial Attacks Using High-Level Representation Guided Denoiser </th> 
    <th> <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Liao_Defense_Against_Adversarial_CVPR_2018_paper.pdf">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> On the Robustness of Semantic Segmentation Models to Adversarial Attacks </th> 
    <th> <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Arnab_On_the_Robustness_CVPR_2018_paper.pdf">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Geometric robustness of deep networks: analysis and improvement </th> 
    <th> <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Kanbak_Geometric_Robustness_of_CVPR_2018_paper.pdf">link</a> </th>    
    <th class="tg-yw4l">  </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Provable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope </th> 
    <th> <a href="https://arxiv.org/abs/1711.00851">link</a> </th>    
    <th class="tg-yw4l"> ICML2018  </th>   
  </tr>
  
   <tr>
    <th class="tg-yw4l"> Parseval Networks: Improving Robustness to Adversarial Examples </th> 
    <th> <a href="https://arxiv.org/abs/1704.08847?context=cs">link</a> </th>    
    <th class="tg-yw4l"> ICML2017  </th>   
  </tr>

   <tr>      
    <th class="tg-yw4l"> Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks </th> 
    <th> <a href="https://arxiv.org/pdf/1704.01155.pdf">link</a> </th> 
    <th class="tg-yw4l"> NDSS2018 </th> 
  </tr>
  
   <tr>      
    <th class="tg-yw4l"> Certified Defenses against Adversarial Examples </th> 
    <th> <a href="https://arxiv.org/abs/1801.09344">link</a> </th> 
    <th class="tg-yw4l"> ICLR2018 </th> 
  </tr>
  
   <tr>      
    <th class="tg-yw4l"> Combating Adversarial Attacks Using Sparse Representations </th> 
    <th> <a href="https://arxiv.org/abs/1803.03880">link</a> </th> 
    <th class="tg-yw4l"> ICLR2018 </th> 
  </tr>
  
   <tr>      
    <th class="tg-yw4l"> Countering Adversarial Images using Input Transformations </th> 
    <th> <a href="https://arxiv.org/abs/1711.00117">link</a> </th> 
    <th class="tg-yw4l"> ICLR2018 </th> 
  </tr>
  
   <tr>      
    <th class="tg-yw4l">Defense-GAN- Protecting Classifiers Against Adversarial Attacks Using Generative Models </th> 
    <th> <a href="https://arxiv.org/abs/1805.06605">link</a> </th> 
    <th class="tg-yw4l"> ICLR2018 </th> 
  </tr>
  
   <tr>      
    <th class="tg-yw4l">Ensemble Adversarial Training- Attacks and Defenses</th> 
    <th> <a href="https://arxiv.org/abs/1705.07204">link</a> </th> 
    <th class="tg-yw4l"> ICLR2018 </th> 
  </tr>
  
   <tr>      
    <th class="tg-yw4l">Mitigating Adversarial Effects Through Randomization</th> 
    <th> <a href="https://arxiv.org/abs/1711.01991">link</a> </th> 
    <th class="tg-yw4l"> ICLR2018 </th> 
  </tr>
  
  
   <tr>      
    <th class="tg-yw4l">Stochastic Activation Pruning for Robust Adversarial Defense</th> 
    <th> <a href="https://arxiv.org/abs/1803.01442">link</a> </th> 
    <th class="tg-yw4l"> ICLR2018 </th> 
  </tr>
    
   <tr>      
    <th class="tg-yw4l">Thermometer Encoding- One Hot Way To Resist Adversarial Examples</th> 
    <th> <a href="https://openreview.net/forum?id=S18Su--CW">link</a> </th> 
    <th class="tg-yw4l"> ICLR2018 </th> 
  </tr>
    
   <tr>      
    <th class="tg-yw4l">Towards Deep Learning Models Resistant to Adversarial Attacks</th> 
    <th> <a href="https://arxiv.org/abs/1706.06083">link</a> </th> 
    <th class="tg-yw4l"> ICLR2018 </th> 
  </tr>
  
   <tr>      
    <th class="tg-yw4l">On Detecting Adversarial Perturbations</th> 
    <th> <a href="https://arxiv.org/abs/1702.04267">link</a> </th> 
    <th class="tg-yw4l"> ICLR2017 </th> 
  </tr>
  
  <tr>      
    <th class="tg-yw4l">Adversary Resistant Deep Neural Networks with an Application to Malware Detection</th> 
    <th> <a href="https://arxiv.org/abs/1610.01239">link</a> </th> 
    <th class="tg-yw4l"> KDD2017 </th> 
  </tr>
    	
	
</table>

<a href="https://github.com/TrustAI/Literature-on-DNN-Verification-and-Testing">Back</a>
  
</body>
</html>
